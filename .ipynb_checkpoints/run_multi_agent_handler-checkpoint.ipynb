{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bm_multi_env import Game\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import display\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Game(5, 7)\n",
    "board, players = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:04<00:00, 20183.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_success = 0\n",
    "for i in tqdm(range(100000)):\n",
    "    board, players = env.reset()\n",
    "    while not done:\n",
    "        old_score = players[0].score\n",
    "        board, done, players, bombs = env.step([np.random.choice([0,1,2,3,4,5]), 0])\n",
    "        new_score = players[0].score\n",
    "        if new_score - old_score > 0:\n",
    "            total_success += 1\n",
    "            break\n",
    "\n",
    "\n",
    "print(total_success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "env = Game(5 ,7)\n",
    "board, players = env.reset()\n",
    "\n",
    "\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=2, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=2, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=2, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 2, stride = 1):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        \n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.head(x.view(x.size(0), -1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 100\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = 6\n",
    "\n",
    "policy_net = DQN(5, 7, n_actions).to(device)\n",
    "target_net = DQN(5, 7, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(1000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2679,  0.3345,  0.0178, -0.8736,  0.4867, -0.6114]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net(torch.tensor(board).unsqueeze(0).unsqueeze(0).float())\n",
    "#torch.tensor(board).unsqueeze(0).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    \n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_tensor(state):\n",
    "    return torch.tensor(state).unsqueeze(0).unsqueeze(0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 165/5000 [00:59<29:03,  2.77it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-420-bd78b4bc1fa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Perform one step of the optimization (on the target network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mreward_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-418-16be34ab3551>\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Optimize the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/beta-colab/pythonenv3.8/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/beta-colab/pythonenv3.8/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_episodes = 50000\n",
    "reward_sum = 0\n",
    "for i_episode in tqdm(range(num_episodes)):\n",
    "    # Initialize the environment and state\n",
    "    board, players = env.reset()\n",
    "    last_screen = board.copy()\n",
    "    current_screen = board.copy()\n",
    "    state = torch.tensor(board).unsqueeze(0).unsqueeze(0).float()\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        old_score = env.players[0].score\n",
    "        action = select_action(state)\n",
    "        board, done, players, _ = env.step([action.item(), 0])\n",
    "        new_score = env.players[0].score\n",
    "        reward = (new_score - old_score) - 1\n",
    "        #_, reward, done, _ = env.step([action.item(), 0])\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen.copy()\n",
    "        current_screen = board.copy()\n",
    "        if not done:\n",
    "            next_state = torch.tensor(board.copy()).unsqueeze(0).unsqueeze(0).float()\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            reward_sum += new_score\n",
    "            episode_durations.append(reward_sum)\n",
    "            break\n",
    "            \n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe2b6e1f1f0>]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(episode_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
